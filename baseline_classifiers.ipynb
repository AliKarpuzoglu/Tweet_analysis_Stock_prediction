{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import naive_bayes, svm, metrics \n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "# reset colwitdth options when running all cells \n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (all tweets and corresponding stock prices)\n",
    "... and group by days / timestemps even groups weren't used yet in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('processed_data/data_less_strict_merged.json')\n",
    "# remove columns that were unexpectedly generated during saving\n",
    "# data.drop(columns=['level_0', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceUp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>[]</td>\n",
       "      <td>Tesla's scant disclosures leave Wall Street gu...</td>\n",
       "      <td>Automotive News</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>312.00</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>[]</td>\n",
       "      <td>Traditional truck maker Navigant claims it wil...</td>\n",
       "      <td>AukeHoekstra</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>321.00</td>\n",
       "      <td>317.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>[]</td>\n",
       "      <td>Tesla Falls After Musk Delays Model 3 Producti...</td>\n",
       "      <td>BRANDON Edwards</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>312.87</td>\n",
       "      <td>314.62</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>[]</td>\n",
       "      <td>Nearly 80% Of Electric Cars (Minus Tesla) Are ...</td>\n",
       "      <td>InsideEVs</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>316.62</td>\n",
       "      <td>316.58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>[]</td>\n",
       "      <td>En 1926, Nikola Tesla predijo el smartphone co...</td>\n",
       "      <td>Gizmodo en Español</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>316.00</td>\n",
       "      <td>336.41</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>[]</td>\n",
       "      <td>How is that awful?  It’s the same advice I giv...</td>\n",
       "      <td>Gregg Peppel</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>278.51</td>\n",
       "      <td>283.76</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>[Autopilot, GuidaAutonoma, TeslaModel3, tuttotek]</td>\n",
       "      <td>Tesla Model 3: tour mondiale con schianto fina...</td>\n",
       "      <td>tuttoteK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>283.29</td>\n",
       "      <td>291.72</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>[]</td>\n",
       "      <td>My first time in a @Tesla and my my what an aw...</td>\n",
       "      <td>Rakesh Nagaraj</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>287.21</td>\n",
       "      <td>284.73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>[]</td>\n",
       "      <td>Blood spray detection would works. (Kidding......</td>\n",
       "      <td>Tom Robinson</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.86</td>\n",
       "      <td>291.82</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>[]</td>\n",
       "      <td>Vi un Tesla en la autopista con mis propios oj...</td>\n",
       "      <td>Σοφία</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294.34</td>\n",
       "      <td>296.74</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     hashtags  \\\n",
       "timestamp                                                       \n",
       "2018-01-02                                                 []   \n",
       "2018-01-03                                                 []   \n",
       "2018-01-04                                                 []   \n",
       "2018-01-05                                                 []   \n",
       "2018-01-08                                                 []   \n",
       "...                                                       ...   \n",
       "2018-05-29                                                 []   \n",
       "2018-05-30  [Autopilot, GuidaAutonoma, TeslaModel3, tuttotek]   \n",
       "2018-05-31                                                 []   \n",
       "2018-06-01                                                 []   \n",
       "2018-06-04                                                 []   \n",
       "\n",
       "                                                         text  \\\n",
       "timestamp                                                       \n",
       "2018-01-02  Tesla's scant disclosures leave Wall Street gu...   \n",
       "2018-01-03  Traditional truck maker Navigant claims it wil...   \n",
       "2018-01-04  Tesla Falls After Musk Delays Model 3 Producti...   \n",
       "2018-01-05  Nearly 80% Of Electric Cars (Minus Tesla) Are ...   \n",
       "2018-01-08  En 1926, Nikola Tesla predijo el smartphone co...   \n",
       "...                                                       ...   \n",
       "2018-05-29  How is that awful?  It’s the same advice I giv...   \n",
       "2018-05-30  Tesla Model 3: tour mondiale con schianto fina...   \n",
       "2018-05-31  My first time in a @Tesla and my my what an aw...   \n",
       "2018-06-01  Blood spray detection would works. (Kidding......   \n",
       "2018-06-04  Vi un Tesla en la autopista con mis propios oj...   \n",
       "\n",
       "                      username  likes  replies  retweets    Open   Close  \\\n",
       "timestamp                                                                  \n",
       "2018-01-02     Automotive News     11        2         9  312.00  320.53   \n",
       "2018-01-03        AukeHoekstra     44        6        25  321.00  317.25   \n",
       "2018-01-04     BRANDON Edwards      1        1         1  312.87  314.62   \n",
       "2018-01-05           InsideEVs      8        3         3  316.62  316.58   \n",
       "2018-01-08  Gizmodo en Español     84        1        58  316.00  336.41   \n",
       "...                        ...    ...      ...       ...     ...     ...   \n",
       "2018-05-29        Gregg Peppel     31        1         0  278.51  283.76   \n",
       "2018-05-30            tuttoteK      0        0         1  283.29  291.72   \n",
       "2018-05-31      Rakesh Nagaraj     10        2         1  287.21  284.73   \n",
       "2018-06-01        Tom Robinson      2        0         0  285.86  291.82   \n",
       "2018-06-04               Σοφία      3        0         0  294.34  296.74   \n",
       "\n",
       "            PriceUp  \n",
       "timestamp            \n",
       "2018-01-02     True  \n",
       "2018-01-03    False  \n",
       "2018-01-04     True  \n",
       "2018-01-05    False  \n",
       "2018-01-08     True  \n",
       "...             ...  \n",
       "2018-05-29     True  \n",
       "2018-05-30     True  \n",
       "2018-05-31    False  \n",
       "2018-06-01     True  \n",
       "2018-06-04     True  \n",
       "\n",
       "[103 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group data by day\n",
    "daily_data = data.groupby(data['timestamp'])\n",
    "daily_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-02 00:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get groups' names\n",
    "daily_data.groups.keys()\n",
    "groups = [name for name, _ in daily_data]\n",
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>Tesla's scant disclosures leave Wall Street gu...</td>\n",
       "      <td>Automotive News</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>Elon Musk and Tesla said earlier this year tha...</td>\n",
       "      <td>Martin Baccardax</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ManAndBeast, drivefreehttps]</td>\n",
       "      <td>An amazing accomplishment and a testament to b...</td>\n",
       "      <td>Tesla Model S60</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>Tesla's scant disclosures on the Model 3 leave...</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>Like Abraham Lincoln? Tesla? Edison? Traveling...</td>\n",
       "      <td>Science Traveler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        hashtags  \\\n",
       "0                             []   \n",
       "1                             []   \n",
       "2  [ManAndBeast, drivefreehttps]   \n",
       "3                             []   \n",
       "4                             []   \n",
       "\n",
       "                                                text          username  likes  \\\n",
       "0  Tesla's scant disclosures leave Wall Street gu...   Automotive News     11   \n",
       "1  Elon Musk and Tesla said earlier this year tha...  Martin Baccardax      2   \n",
       "2  An amazing accomplishment and a testament to b...   Tesla Model S60      7   \n",
       "3  Tesla's scant disclosures on the Model 3 leave...      Businessweek      2   \n",
       "4  Like Abraham Lincoln? Tesla? Edison? Traveling...  Science Traveler      0   \n",
       "\n",
       "   replies  retweets   Open   Close  PriceUp  \n",
       "0        2         9  312.0  320.53     True  \n",
       "1        0         1  312.0  320.53     True  \n",
       "2        0         2  312.0  320.53     True  \n",
       "3        0         2  312.0  320.53     True  \n",
       "4        0         3  312.0  320.53     True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tweets from the first day\n",
    "first_day_data = daily_data.get_group(groups[0])\n",
    "first_day_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first very simple classifier\n",
    "Use each tweet and predict whether it was written on a day where stock price has grown (PriceUp == True) or not\n",
    "\n",
    "As classificators use the algorithms learned in class: naive bayes and SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set size:\t 150042\n",
      "Test Set size:\t\t  26478\n"
     ]
    }
   ],
   "source": [
    "# generate the train and test sets\n",
    "tweets_train, tweets_test, labels_train, labels_test = train_test_split(data['text'], data['PriceUp'], \n",
    "                                                   test_size=0.15, random_state=333, shuffle=False)\n",
    "# now shuffle the data to decorrelate them for training and testing\n",
    "tweets_train, labels_train = shuffle(tweets_train, labels_train)\n",
    "tweets_test, labels_test = shuffle(tweets_test, labels_test)\n",
    "\n",
    "print('Training Set size:\\t', len(tweets_train))\n",
    "print('Test Set size:\\t\\t ', len(tweets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150042, 237399)\n",
      "Size of the vocabulary:  237399\n"
     ]
    }
   ],
   "source": [
    "# vectorize train and test data with TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_matrix = vectorizer.fit_transform(tweets_train)\n",
    "test_matrix = vectorizer.transform(tweets_test)\n",
    "print(train_matrix.shape)\n",
    "type(train_matrix)\n",
    "print(\"Size of the vocabulary: \", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Our vector space is far higher than the number of training data. Therefore the classifier will for sure overfit and not generalize well to the test data at all. We can still use it as a simple baseline.\n",
    "\n",
    "BUT BEFORE...\n",
    "### Refit the vectorizer with most important tweets\n",
    "In order to decrease the vocabulary of the vectorizer, we first filter out the most important tweets (min. two retweets or five likes or five replies) and use them to determine the vocabulary of the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of considered tweets:  3901\n"
     ]
    }
   ],
   "source": [
    "vocab_data = data[(data['retweets']>25) &\n",
    "                  ((data['likes']>25) | (data['replies']>10))]\n",
    "\n",
    "# display whole tweet texts\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"Number of considered tweets: \", vocab_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the vocabulary:  17968\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(vocab_data['text'])\n",
    "print(\"Length of the vocabulary: \", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150042, 17968)\n"
     ]
    }
   ],
   "source": [
    "# now transform the train and test set with the limited vocabulary\n",
    "train_matrix = vectorizer.transform(tweets_train)\n",
    "test_matrix = vectorizer.transform(tweets_test)\n",
    "print(train_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have almost ten times more data than dimension in vector space. This is definitely better compared with having less data as dimensions, but is expected to still not be enough to train a good model. \n",
    "\n",
    "We still try it and use it as a simple baseline, that we'll try to overcome!\n",
    "Also an SVM is reported to be effective even when the number of dimensions is greater than the number of samples, so we definitely give it a try.\n",
    "\n",
    "Normalization of data may not be necessary, as a TfIdf vectorizer outputs vectors with values between 0 and 1. But we should better check the mean. Having a unit variance will not work as we are dealing with a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3.76929458e-03, 6.26847596e-05, 5.72185745e-06, ...,\n",
       "         3.32637506e-06, 6.53244777e-06, 1.03345192e-05]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.mean(train_matrix, axis=0)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use min-max normalization instead\n",
    "# doesn't work because of mins and maxs being sparse matrices\n",
    "mins = np.amin(train_matrix, axis=0)\n",
    "maxs = np.max(train_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=100000000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = svm.LinearSVC(C=1.5, max_iter=int(1e8))\n",
    "svm_classifier.fit(train_matrix, labels_train)\n",
    "\n",
    "# not enough memory to perform\n",
    "# nb_classifier = naive_bayes.GaussianNB()\n",
    "# nb_classifier.fit(train_matrix.toarray(), labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if training was successful\n",
    "As we have not enough data, a working classifier should overfit to the training data and hence perfectly predict the labels of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t\tSVM \t\tNaive Bayes\n",
      "Acc \t\t 0.676 \t\t 0.000\n",
      "Prec \t\t 0.678 \t\t 0.000\n",
      "Rec \t\t 0.698 \t\t 0.000\n",
      "FMeas \t\t 0.688 \t\t 0.000\n"
     ]
    }
   ],
   "source": [
    "# check if classifier has really overfitted to the data by testing it on the training data\n",
    "preds_svm = svm_classifier.predict(train_matrix)\n",
    "svm_acc = metrics.accuracy_score(labels_train, preds_svm)\n",
    "\n",
    "# preds_nb = nb_classifier.predict(train_matrix.toarray())\n",
    "# nb_acc = metrics.accuracy_score(labels_train, preds_nb)\n",
    "# A NB classifier could not be trained due to unfulfilled memory requirements\n",
    "nb_acc = 0\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_train, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = 0,0,0,0 # \\\n",
    "# metrics.precision_recall_fscore_support(labels_train, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD: Check! Both classifiers reach an almost 100% accuracy on the training data. Therefore we can be sure, the classifier really learned a model based on the training data.\n",
    "\n",
    "UPDATED: The SVM classifier reaches a performance that is clearly over random guessing. Indeed, the amount of data and the usage of a simple SVM, no complex kernels, no hyperparameter tuning etc. do not allow to get better results.\n",
    "### Evaluate learned models on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t\tSVM \t\tNaive Bayes\n",
      "Acc \t\t 0.497 \t\t 0.000\n",
      "Prec \t\t 0.542 \t\t 0.000\n",
      "Rec \t\t 0.437 \t\t 0.000\n",
      "FMeas \t\t 0.484 \t\t 0.000\n"
     ]
    }
   ],
   "source": [
    "# test the classifiers\n",
    "preds_svm = svm_classifier.predict(test_matrix)\n",
    "svm_acc = metrics.accuracy_score(labels_test, preds_svm)\n",
    "\n",
    "# preds_nb = nb_classifier.predict(test_matrix.toarray())\n",
    "# nb_acc = metrics.accuracy_score(labels_test, preds_nb)\n",
    "nb_acc = 0\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_test, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = 0,0,0,0 # \\\n",
    "# metrics.precision_recall_fscore_support(labels_test, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a statement about the results, we first have to look at the distribution of labels in the test dataset.\n",
    "An even simpler baseline we can use to compare our results with is a classifier that constantly predicts the class that is most common in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classifier that always predicts 'True' would get an accuracy of: 0.540\n"
     ]
    }
   ],
   "source": [
    "num_trues, num_falses = labels_test.value_counts()\n",
    "print(\"A classifier that always predicts 'True' would get an accuracy of: %.3f\" % (num_trues/labels_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the first sight, our classifier seems to have learned a very little bit, having an accuracy of 55.4 and 54.9 percent while the constant prediction would lead to 53.7 percent. In our case of predicting whether the stock price will close higher that it has opened based on a tweet, recall is much more important to us.\n",
    "\n",
    "Altogether the difference is too insignificant and is expected to be not reproducible when using different hyper parameters like the size of the training set, another random seed etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update**: After playing a bit with hyperparameters, we can say that the accuracy of our classifiers is always slightly above the constant value predictor. The SVM classifier always reaches a higher accuracy than the NB classifier as well as a higher Recall, which is especially important for our goal as we want to avoid false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** It looks like this very simple classifier already has learned some patterns in the data, which is unexpected, but can be explained as follows: \n",
    "\n",
    "- test and training data are expected to be correlated, as the test data contains tweets from days which we've already trained on. A better evaluation: use data of new days\n",
    "- Think about it again: As we're predicting only if a tweet was written on a good day for TSLA and do not consider the time a tweet was written at, it is likely to happen, that people write about the positive development of the stock price...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Update:\n",
    "After no longer shuffling the data on the train-test-split, the evaluation of our model results in the expected accuracy of below 50%. With shuffling the data before, the test set contained tweets from the same days that were already used during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
