{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import naive_bayes, svm, metrics\n",
    "import pandas as pd\n",
    "# reset colwitdth options when running all cells \n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (all tweets and corresponding stock prices)\n",
    "... and group by days / timestemps even groups weren't used yet in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('processed_data/data_merged.json')\n",
    "# remove columns that were unexpectedly generated during saving\n",
    "# data.drop(columns=['level_0', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceUp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[Tesla, ModelS]</td>\n",
       "      <td>In the past 2 years, I've driven 18,823 miles ...</td>\n",
       "      <td>Ben Sullins ðŸ’ª</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>312.00</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>DÃ­a de piernas ... Estrenando mallas...#Tesla ...</td>\n",
       "      <td>El CaZador</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>321.00</td>\n",
       "      <td>317.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>[Innovation, Tesla, electricvehicles, Cars, br...</td>\n",
       "      <td>This is awesome! New brand technology #Innovat...</td>\n",
       "      <td>Gabriela MascarÃ³</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>312.87</td>\n",
       "      <td>314.62</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>[Tesla, TeslaModel3]</td>\n",
       "      <td>#Tesla #TeslaModel3 hahapic.twitter.com/DMlxOf...</td>\n",
       "      <td>WtaFiGO</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>316.62</td>\n",
       "      <td>316.58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Tesla Planning Supercharger Station With â€˜Old ...</td>\n",
       "      <td>Tesla Motors Club</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>316.00</td>\n",
       "      <td>336.41</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>[Tesla, Elektroautopic]</td>\n",
       "      <td>#Tesla Model 3: Europa-Start \"erste JahreshÃ¤lf...</td>\n",
       "      <td>ecomento.de</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>278.51</td>\n",
       "      <td>283.76</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Oh well... in case you were wondering why @Tes...</td>\n",
       "      <td>Safer Vehicles Proved</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>283.29</td>\n",
       "      <td>291.72</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Take comfort #Tesla friends.  All the alleged ...</td>\n",
       "      <td>Groggy T. Bear</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>287.21</td>\n",
       "      <td>284.73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>[FBI, Tesla]</td>\n",
       "      <td>SegÃºn documento desclasificado del #FBI Niko...</td>\n",
       "      <td>Misterio Desconocido</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>285.86</td>\n",
       "      <td>291.82</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Voici le ModÃ¨le S familial que #Tesla ne veut ...</td>\n",
       "      <td>Les ðŸš˜ ðŸ”Œ</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>294.34</td>\n",
       "      <td>296.74</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     hashtags  \\\n",
       "timestamp                                                       \n",
       "2018-01-02                                    [Tesla, ModelS]   \n",
       "2018-01-03                                            [Tesla]   \n",
       "2018-01-04  [Innovation, Tesla, electricvehicles, Cars, br...   \n",
       "2018-01-05                               [Tesla, TeslaModel3]   \n",
       "2018-01-08                                            [Tesla]   \n",
       "...                                                       ...   \n",
       "2018-05-29                            [Tesla, Elektroautopic]   \n",
       "2018-05-30                                            [Tesla]   \n",
       "2018-05-31                                            [Tesla]   \n",
       "2018-06-01                                       [FBI, Tesla]   \n",
       "2018-06-04                                            [Tesla]   \n",
       "\n",
       "                                                         text  \\\n",
       "timestamp                                                       \n",
       "2018-01-02  In the past 2 years, I've driven 18,823 miles ...   \n",
       "2018-01-03  DÃ­a de piernas ... Estrenando mallas...#Tesla ...   \n",
       "2018-01-04  This is awesome! New brand technology #Innovat...   \n",
       "2018-01-05  #Tesla #TeslaModel3 hahapic.twitter.com/DMlxOf...   \n",
       "2018-01-08  Tesla Planning Supercharger Station With â€˜Old ...   \n",
       "...                                                       ...   \n",
       "2018-05-29  #Tesla Model 3: Europa-Start \"erste JahreshÃ¤lf...   \n",
       "2018-05-30  Oh well... in case you were wondering why @Tes...   \n",
       "2018-05-31  Take comfort #Tesla friends.  All the alleged ...   \n",
       "2018-06-01  Â  SegÃºn documento desclasificado del #FBI Niko...   \n",
       "2018-06-04  Voici le ModÃ¨le S familial que #Tesla ne veut ...   \n",
       "\n",
       "                         username  likes  replies  retweets    Open   Close  \\\n",
       "timestamp                                                                     \n",
       "2018-01-02          Ben Sullins ðŸ’ª    110        6        10  312.00  320.53   \n",
       "2018-01-03             El CaZador    107        3         4  321.00  317.25   \n",
       "2018-01-04       Gabriela MascarÃ³      6        1         3  312.87  314.62   \n",
       "2018-01-05                WtaFiGO     19        1         7  316.62  316.58   \n",
       "2018-01-08      Tesla Motors Club    132        4        16  316.00  336.41   \n",
       "...                           ...    ...      ...       ...     ...     ...   \n",
       "2018-05-29            ecomento.de      3        2         1  278.51  283.76   \n",
       "2018-05-30  Safer Vehicles Proved     27        4         9  283.29  291.72   \n",
       "2018-05-31         Groggy T. Bear     22        4         3  287.21  284.73   \n",
       "2018-06-01   Misterio Desconocido     40        3        14  285.86  291.82   \n",
       "2018-06-04                Les ðŸš˜ ðŸ”Œ      2        3         1  294.34  296.74   \n",
       "\n",
       "            PriceUp  \n",
       "timestamp            \n",
       "2018-01-02     True  \n",
       "2018-01-03    False  \n",
       "2018-01-04     True  \n",
       "2018-01-05    False  \n",
       "2018-01-08     True  \n",
       "...             ...  \n",
       "2018-05-29     True  \n",
       "2018-05-30     True  \n",
       "2018-05-31    False  \n",
       "2018-06-01     True  \n",
       "2018-06-04     True  \n",
       "\n",
       "[103 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group data by day\n",
    "daily_data = data.groupby(data['timestamp'])\n",
    "daily_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-02 00:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get groups' names\n",
    "daily_data.groups.keys()\n",
    "groups = [name for name, _ in daily_data]\n",
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Tesla, ModelS]</td>\n",
       "      <td>In the past 2 years, I've driven 18,823 miles ...</td>\n",
       "      <td>Ben Sullins ðŸ’ª</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Tesla, P90D, Blog, Youtube]</td>\n",
       "      <td>Ya estamos en @louesfera probando un #Tesla #P...</td>\n",
       "      <td>Fco Javier</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Snapchat, Uber, Twitter, Facebook, Tesla, Goo...</td>\n",
       "      <td>Here's how old these companies will be turning...</td>\n",
       "      <td>Imran</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Muskwatchpic]</td>\n",
       "      <td>From SpaceX to Tesla, here are our biggest que...</td>\n",
       "      <td>Nerdist</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[Braunschweig, VW, Tesla]</td>\n",
       "      <td>In #Braunschweig produziert #VW seine Batterie...</td>\n",
       "      <td>HAZ</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hashtags  \\\n",
       "0                                    [Tesla, ModelS]   \n",
       "1                       [Tesla, P90D, Blog, Youtube]   \n",
       "2  [Snapchat, Uber, Twitter, Facebook, Tesla, Goo...   \n",
       "3                                     [Muskwatchpic]   \n",
       "4                          [Braunschweig, VW, Tesla]   \n",
       "\n",
       "                                                text       username  likes  \\\n",
       "0  In the past 2 years, I've driven 18,823 miles ...  Ben Sullins ðŸ’ª    110   \n",
       "1  Ya estamos en @louesfera probando un #Tesla #P...     Fco Javier      2   \n",
       "2  Here's how old these companies will be turning...          Imran     53   \n",
       "3  From SpaceX to Tesla, here are our biggest que...        Nerdist     37   \n",
       "4  In #Braunschweig produziert #VW seine Batterie...            HAZ      5   \n",
       "\n",
       "   replies  retweets   Open   Close  PriceUp  \n",
       "0        6        10  312.0  320.53     True  \n",
       "1        1         2  312.0  320.53     True  \n",
       "2        7        41  312.0  320.53     True  \n",
       "3        5        10  312.0  320.53     True  \n",
       "4        3         2  312.0  320.53     True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tweets from the first day\n",
    "first_day_data = daily_data.get_group(groups[0])\n",
    "first_day_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first very simple classifier\n",
    "Use each tweet and predict whether it was written on a day where stock price has grown (PriceUp == True) or not\n",
    "\n",
    "As classificators use the algorithms learned in class: naive bayes and SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4206"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the train and test sets\n",
    "tweets_train, tweets_test, labels_train, labels_test = train_test_split(data['text'], data['PriceUp'], \n",
    "                                                   test_size=0.15, random_state=333, shuffle=True)\n",
    "len(tweets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4206, 22108)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize train and test data with TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_matrix = vectorizer.fit_transform(tweets_train)\n",
    "test_matrix = vectorizer.transform(tweets_test)\n",
    "print(train_matrix.shape)\n",
    "type(train_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Our vector space is far higher than the number of training data. Therefore the classifier will for sure overfit and not generalize well to the test data at all. We can still use it as a simple baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = svm.LinearSVC(max_iter=int(1e6))\n",
    "svm_classifier.fit(train_matrix, labels_train)\n",
    "\n",
    "nb_classifier = naive_bayes.GaussianNB()\n",
    "nb_classifier.fit(train_matrix.toarray(), labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if training was successful\n",
    "As we have not enough data, a working classifier should overfit to the training data and hence perfectly predict the labels of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t\tSVM \t\tNaive Bayes\n",
      "Acc \t\t 0.996 \t\t 0.977\n",
      "Prec \t\t 0.995 \t\t 1.000\n",
      "Rec \t\t 0.997 \t\t 0.957\n",
      "FMeas \t\t 0.996 \t\t 0.978\n"
     ]
    }
   ],
   "source": [
    "# check if classifier has really overfitted to the data by testing it on the training data\n",
    "preds_svm = svm_classifier.predict(train_matrix)\n",
    "svm_acc = metrics.accuracy_score(labels_train, preds_svm)\n",
    "\n",
    "preds_nb = nb_classifier.predict(train_matrix.toarray())\n",
    "nb_acc = metrics.accuracy_score(labels_train, preds_nb)\n",
    "\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_train, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_train, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check! Both classifiers reach an almost 100% accuracy on the training data. Therefore we can be sure, the classifier really learned a model based on the training data.\n",
    "\n",
    "### Test learned models on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t\tSVM \t\tNaive Bayes\n",
      "Acc \t\t 0.569 \t\t 0.556\n",
      "Prec \t\t 0.584 \t\t 0.592\n",
      "Rec \t\t 0.599 \t\t 0.473\n",
      "FMeas \t\t 0.592 \t\t 0.526\n"
     ]
    }
   ],
   "source": [
    "# test the classifiers\n",
    "preds_svm = svm_classifier.predict(test_matrix)\n",
    "svm_acc = metrics.accuracy_score(labels_test, preds_svm)\n",
    "\n",
    "preds_nb = nb_classifier.predict(test_matrix.toarray())\n",
    "nb_acc = metrics.accuracy_score(labels_test, preds_nb)\n",
    "\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_test, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_test, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a statement about the results, we first have to look at the distribution of labels in the test dataset.\n",
    "An even simpler baseline we can use to compare our results with is a classifier that constantly predicts the class that is most common in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classifier that always predicts 'True' would get an accuracy of: 0.521\n"
     ]
    }
   ],
   "source": [
    "num_trues, num_falses = labels_test.value_counts()\n",
    "print(\"A classifier that always predicts 'True' would get an accuracy of: %.3f\" % (num_trues/labels_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the first sight, our classifier seems to have learned a very little bit, having an accuracy of 55.4 and 54.9 percent while the constant prediction would lead to 53.7 percent. In our case of predicting whether the stock price will close higher that it has opened based on a tweet, recall is much more important to us.\n",
    "\n",
    "Altogether the difference is too insignificant and is expected to be not reproducible when using different hyper parameters like the size of the training set, another random seed etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update**: After playing a bit with hyperparameters, we can say that the accuracy of our classifiers is always slightly above the constant value predictor. The SVM classifier always reaches a higher accuracy than the NB classifier as well as a higher Recall, which is especially important for our goal as we want to avoid false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** It looks like this very simple classifier already has learned some patterns in the data, which is unexpected, but can be explained as follows: \n",
    "\n",
    "- test and training data are expected to be correlated, as the test data contains tweets from days which we've already trained on. A better evaluation: use data of new days\n",
    "- Think about it again: As we're predicting only if a tweet was written on a good day for TSLA and do not consider the time a tweet was written at, it is likely to happen, that people write about the positive development of the stock price...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
