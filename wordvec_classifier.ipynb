{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import naive_bayes, svm, metrics\n",
    "import pandas as pd\n",
    "# reset colwitdth options when running all cells \n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and group by day (all tweets and corresponding stock prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>[Tesla, Model3pic]</td>\n",
       "      <td>Report: Tesla Has Refunded 23% of Model 3 Depo...</td>\n",
       "      <td>Tesla Motors Club</td>\n",
       "      <td>91</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>294.34</td>\n",
       "      <td>296.74</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>[Tesla, NikolaTeslapic]</td>\n",
       "      <td>Make electricity free again! #Tesla #NikolaTes...</td>\n",
       "      <td>Mr A üé∂üéµ ‚ôè</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>294.34</td>\n",
       "      <td>296.74</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>[Tesla, ElonMusk, CFD, forex, equitypic]</td>\n",
       "      <td>#Tesla #ElonMusk #CFD #forex #equitypic.twitte...</td>\n",
       "      <td>The Utkarsh</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>294.34</td>\n",
       "      <td>296.74</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp                                  hashtags  \\\n",
       "4946 2018-06-04                        [Tesla, Model3pic]   \n",
       "4947 2018-06-04                   [Tesla, NikolaTeslapic]   \n",
       "4948 2018-06-04  [Tesla, ElonMusk, CFD, forex, equitypic]   \n",
       "\n",
       "                                                   text           username  \\\n",
       "4946  Report: Tesla Has Refunded 23% of Model 3 Depo...  Tesla Motors Club   \n",
       "4947  Make electricity free again! #Tesla #NikolaTes...          Mr A üé∂üéµ ‚ôè   \n",
       "4948  #Tesla #ElonMusk #CFD #forex #equitypic.twitte...        The Utkarsh   \n",
       "\n",
       "      likes  replies  retweets    Open   Close  PriceUp  \n",
       "4946     91       13        13  294.34  296.74     True  \n",
       "4947      2        1         1  294.34  296.74     True  \n",
       "4948      2        1         1  294.34  296.74     True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('processed_data/data_merged.json')\n",
    "# remove columns that were unexpectedly generated during saving\n",
    "# data.drop(columns=['level_0', 'index'], inplace=True)\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[Tesla, ModelS]</td>\n",
       "      <td>In the past 2 years, I've driven 18,823 miles ...</td>\n",
       "      <td>Ben Sullins üí™</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>312.00</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>D√≠a de piernas ... Estrenando mallas...#Tesla ...</td>\n",
       "      <td>El CaZador</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>321.00</td>\n",
       "      <td>317.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>[Innovation, Tesla, electricvehicles, Cars, br...</td>\n",
       "      <td>This is awesome! New brand technology #Innovat...</td>\n",
       "      <td>Gabriela Mascar√≥</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>312.87</td>\n",
       "      <td>314.62</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>[Tesla, TeslaModel3]</td>\n",
       "      <td>#Tesla #TeslaModel3 hahapic.twitter.com/DMlxOf...</td>\n",
       "      <td>WtaFiGO</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>316.62</td>\n",
       "      <td>316.58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Tesla Planning Supercharger Station With ‚ÄòOld ...</td>\n",
       "      <td>Tesla Motors Club</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>316.00</td>\n",
       "      <td>336.41</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>[Tesla, Elektroautopic]</td>\n",
       "      <td>#Tesla Model 3: Europa-Start \"erste Jahresh√§lf...</td>\n",
       "      <td>ecomento.de</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>278.51</td>\n",
       "      <td>283.76</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Oh well... in case you were wondering why @Tes...</td>\n",
       "      <td>Safer Vehicles Proved</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>283.29</td>\n",
       "      <td>291.72</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Take comfort #Tesla friends.  All the alleged ...</td>\n",
       "      <td>Groggy T. Bear</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>287.21</td>\n",
       "      <td>284.73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>[FBI, Tesla]</td>\n",
       "      <td>Seg√∫n documento desclasificado del #FBI Niko...</td>\n",
       "      <td>Misterio Desconocido</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>285.86</td>\n",
       "      <td>291.82</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>[Tesla]</td>\n",
       "      <td>Voici le Mod√®le S familial que #Tesla ne veut ...</td>\n",
       "      <td>Les üöò üîå</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>294.34</td>\n",
       "      <td>296.74</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp                                           hashtags  \\\n",
       "0   2018-01-02                                    [Tesla, ModelS]   \n",
       "1   2018-01-03                                            [Tesla]   \n",
       "2   2018-01-04  [Innovation, Tesla, electricvehicles, Cars, br...   \n",
       "3   2018-01-05                               [Tesla, TeslaModel3]   \n",
       "4   2018-01-08                                            [Tesla]   \n",
       "..         ...                                                ...   \n",
       "98  2018-05-29                            [Tesla, Elektroautopic]   \n",
       "99  2018-05-30                                            [Tesla]   \n",
       "100 2018-05-31                                            [Tesla]   \n",
       "101 2018-06-01                                       [FBI, Tesla]   \n",
       "102 2018-06-04                                            [Tesla]   \n",
       "\n",
       "                                                  text               username  \\\n",
       "0    In the past 2 years, I've driven 18,823 miles ...          Ben Sullins üí™   \n",
       "1    D√≠a de piernas ... Estrenando mallas...#Tesla ...             El CaZador   \n",
       "2    This is awesome! New brand technology #Innovat...       Gabriela Mascar√≥   \n",
       "3    #Tesla #TeslaModel3 hahapic.twitter.com/DMlxOf...                WtaFiGO   \n",
       "4    Tesla Planning Supercharger Station With ‚ÄòOld ...      Tesla Motors Club   \n",
       "..                                                 ...                    ...   \n",
       "98   #Tesla Model 3: Europa-Start \"erste Jahresh√§lf...            ecomento.de   \n",
       "99   Oh well... in case you were wondering why @Tes...  Safer Vehicles Proved   \n",
       "100  Take comfort #Tesla friends.  All the alleged ...         Groggy T. Bear   \n",
       "101  ¬† Seg√∫n documento desclasificado del #FBI Niko...   Misterio Desconocido   \n",
       "102  Voici le Mod√®le S familial que #Tesla ne veut ...                Les üöò üîå   \n",
       "\n",
       "     likes  replies  retweets    Open   Close  PriceUp  \n",
       "0      110        6        10  312.00  320.53     True  \n",
       "1      107        3         4  321.00  317.25    False  \n",
       "2        6        1         3  312.87  314.62     True  \n",
       "3       19        1         7  316.62  316.58    False  \n",
       "4      132        4        16  316.00  336.41     True  \n",
       "..     ...      ...       ...     ...     ...      ...  \n",
       "98       3        2         1  278.51  283.76     True  \n",
       "99      27        4         9  283.29  291.72     True  \n",
       "100     22        4         3  287.21  284.73    False  \n",
       "101     40        3        14  285.86  291.82     True  \n",
       "102      2        3         1  294.34  296.74     True  \n",
       "\n",
       "[103 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group data by day\n",
    "daily_data = data.groupby(data['timestamp'], as_index=False)\n",
    "daily_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.048544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.304970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             text\n",
       "count  103.000000\n",
       "mean    48.048544\n",
       "std     34.304970\n",
       "min      6.000000\n",
       "25%     34.500000\n",
       "50%     40.000000\n",
       "75%     51.000000\n",
       "max    266.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count tweets per day to see if they're ok'ish distributed\n",
    "tweets_per_day = daily_data['text'].count()\n",
    "tweets_per_day.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have in average almost 50 tweets per day with a minimum of 6 tweets, which should be ok. The standard deviation is quite high too, but since we're so far only looking at individual tweets, this is absolutely ok. Even when we go for averaging the tweets of a single day, it should still be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-02 00:00:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get groups' names\n",
    "daily_data.groups.keys()\n",
    "groups = [name for name, _ in daily_data]\n",
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[Tesla, ModelS]</td>\n",
       "      <td>In the past 2 years, I've driven 18,823 miles ...</td>\n",
       "      <td>Ben Sullins üí™</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[Tesla, P90D, Blog, Youtube]</td>\n",
       "      <td>Ya estamos en @louesfera probando un #Tesla #P...</td>\n",
       "      <td>Fco Javier</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[Snapchat, Uber, Twitter, Facebook, Tesla, Goo...</td>\n",
       "      <td>Here's how old these companies will be turning...</td>\n",
       "      <td>Imran</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[Muskwatchpic]</td>\n",
       "      <td>From SpaceX to Tesla, here are our biggest que...</td>\n",
       "      <td>Nerdist</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[Braunschweig, VW, Tesla]</td>\n",
       "      <td>In #Braunschweig produziert #VW seine Batterie...</td>\n",
       "      <td>HAZ</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>312.0</td>\n",
       "      <td>320.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp                                           hashtags  \\\n",
       "0 2018-01-02                                    [Tesla, ModelS]   \n",
       "1 2018-01-02                       [Tesla, P90D, Blog, Youtube]   \n",
       "2 2018-01-02  [Snapchat, Uber, Twitter, Facebook, Tesla, Goo...   \n",
       "3 2018-01-02                                     [Muskwatchpic]   \n",
       "4 2018-01-02                          [Braunschweig, VW, Tesla]   \n",
       "\n",
       "                                                text       username  likes  \\\n",
       "0  In the past 2 years, I've driven 18,823 miles ...  Ben Sullins üí™    110   \n",
       "1  Ya estamos en @louesfera probando un #Tesla #P...     Fco Javier      2   \n",
       "2  Here's how old these companies will be turning...          Imran     53   \n",
       "3  From SpaceX to Tesla, here are our biggest que...        Nerdist     37   \n",
       "4  In #Braunschweig produziert #VW seine Batterie...            HAZ      5   \n",
       "\n",
       "   replies  retweets   Open   Close  PriceUp  \n",
       "0        6        10  312.0  320.53     True  \n",
       "1        1         2  312.0  320.53     True  \n",
       "2        7        41  312.0  320.53     True  \n",
       "3        5        10  312.0  320.53     True  \n",
       "4        3         2  312.0  320.53     True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tweets from the first day\n",
    "first_day_data = daily_data.get_group(groups[0])\n",
    "first_day_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first very simple classifier using Word Vectors from spacy\n",
    "Use each tweet and predict whether it was written on a day where stock price has grown (PriceUp == True) or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3959"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the train and test sets\n",
    "tweets_train, tweets_test, labels_train, labels_test = train_test_split(data['text'], data['PriceUp'], \n",
    "                                                   test_size=0.2, random_state=333, shuffle=True)\n",
    "len(tweets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue here...\n",
    "Vectorize the data... create a train and test matrix using word vectors from spacy... check if classifiers overfit to the training data... then evaluate on test data using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "except:\n",
    "    import en_core_web_sm\n",
    "    nlp = en_core_web_sm.load()\n",
    "    \n",
    "train_matrix = []\n",
    "test_matrix = []\n",
    "\n",
    "for tweet,priceup in zip(tweets_train,labels_train):\n",
    "    tokens = nlp(tweet)\n",
    "    average_token= tokens[0].vector\n",
    "    for token in tokens[1:]:\n",
    "        average_token = average_token+token.vector\n",
    "    average_token = average_token/len(tokens)\n",
    "    train_matrix.append(average_token)\n",
    "    \n",
    "for tweet,priceup in zip(tweets_test,labels_test):\n",
    "    tokens = nlp(tweet)\n",
    "    average_token= tokens[0].vector\n",
    "    for token in tokens[1:]:\n",
    "        average_token = average_token+token.vector\n",
    "    average_token = average_token/len(tokens)\n",
    "    test_matrix.append(average_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3959 3959\n",
      "990 990\n",
      "<class 'numpy.ndarray'>\n",
      "(96,)\n",
      "One vector:  [ 0.63146317 -0.15021296 -0.69044656  0.65407705  1.191257    0.9622612\n",
      " -0.02600448  0.19858395  1.0466805   1.1214075   0.92656946 -0.7156148\n",
      "  0.4132349  -1.0630354  -1.1714144  -0.656997   -0.30681074  0.38227725\n",
      "  0.04336251 -0.32191426  0.01133227 -0.8395444   0.5322146  -0.18918706\n",
      " -0.6189851  -0.27362013  0.46848962 -1.6048694   0.26084775 -1.0112982\n",
      " -0.02537703 -0.02159977  0.17876668 -0.75421256 -0.6825408  -1.095034\n",
      "  2.3707743  -1.1760559  -0.69888246  0.3179667   1.7626355   0.10533053\n",
      "  0.5835901  -2.1097708  -0.9751415   0.36869898  0.457877   -0.26329026\n",
      " -0.8081718   1.5279149   0.17385235 -1.009767   -0.07693577 -0.22660692\n",
      " -2.05115     1.1694368   0.25987887  1.5791965  -0.3060168  -0.1282751\n",
      " -0.57015914 -0.14959374  1.0731122   0.07965691  0.9205019   0.07158332\n",
      " -0.10366537 -0.91832733 -0.91200864  0.18523099 -0.08648715  0.32651722\n",
      " -0.07397693  0.4862367  -0.5852232   0.32568955  1.3672144   0.08566121\n",
      "  0.09824545  0.69646364  1.0827352  -1.3223166  -0.28098795  0.05961619\n",
      "  1.0641661   1.3868457  -0.2865124  -0.24325253 -0.26968044  0.41489357\n",
      " -0.5530927  -0.4261302   0.25251833  0.2154496   1.1290126   0.49198222]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_matrix),len(labels_train))\n",
    "print(len(test_matrix),len(labels_test))\n",
    "print(type(train_matrix[0]))\n",
    "print(np.shape(train_matrix[0]))\n",
    "print(\"One vector: \", train_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:\n",
      " In the past 2 years, I've driven 18,823 miles and paid $1,120 in fuel costs, giving me a cost per mile of $0.06 in my #Tesla #ModelS\n",
      "Corresponding PriceUp:  True\n"
     ]
    }
   ],
   "source": [
    "# This block is only useful if we want to use all tweets of a day \n",
    "# to predict whether the stock price will close higher than it has opened\n",
    "\n",
    "# vectorize train and test data with word vectors from spacy\n",
    "for day in groups:\n",
    "    # all tweets and priceUp's for a single day\n",
    "    data_single_day = daily_data.get_group(day)\n",
    "    # take only the relevant columns for the classifier\n",
    "    data_single_day = data_single_day[['text', 'PriceUp']]\n",
    "    rows, cols = data_single_day.shape\n",
    "    # individual tweets per day\n",
    "    for row in range(rows):\n",
    "        tweet, price_up = data_single_day.iloc[row][['text','PriceUp']]\n",
    "        # tokenize and get word vectors here\n",
    "        # get the mean of all word vectors to get a vector representation of the tweet\n",
    "        print('Tweet:\\n', tweet)\n",
    "        print('Corresponding PriceUp: ', price_up)        \n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_matrix))\n",
    "print(type(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase number of training examples (by repeating them n times)\n",
    "n = 2\n",
    "train_matrix_n_times = train_matrix*n\n",
    "labels_train_n_times = pd.concat([labels_train]*n, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = svm.LinearSVC(max_iter=int(1e6))\n",
    "svm_classifier.fit(train_matrix_n_times, labels_train_n_times)\n",
    "\n",
    "nb_classifier = naive_bayes.GaussianNB()\n",
    "nb_classifier.fit(train_matrix_n_times, labels_train_n_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if training was successful\n",
    "As we have not enough data, a working classifier should overfit to the training data and hence perfectly predict the labels of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t\tSVM \t\tNaive Bayes\n",
      "Acc \t\t 0.581 \t\t 0.538\n",
      "Prec \t\t 0.588 \t\t 0.566\n",
      "Rec \t\t 0.685 \t\t 0.524\n",
      "FMeas \t\t 0.633 \t\t 0.544\n"
     ]
    }
   ],
   "source": [
    "# check if classifier has really overfitted to the data by testing it on the training data\n",
    "preds_svm = svm_classifier.predict(train_matrix)\n",
    "svm_acc = metrics.accuracy_score(labels_train, preds_svm)\n",
    "\n",
    "preds_nb = nb_classifier.predict(train_matrix)\n",
    "nb_acc = metrics.accuracy_score(labels_train, preds_nb)\n",
    "\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_train, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_train, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "Both classifiers reached quite poor performance when evaluating on even the training set. This could mean, we have no overfitting and have a hope for getting a bit generalization, but we believe there are other problems that can explain this observation: \n",
    "* das Language Model wurde auf anderen Daten trainiert... Die Dimensionen der Vektoren haben alle eine f√ºr unsere Aufgabe irrelevante Bedeutung.\n",
    "* Durschnitt eines Tweets verliert seine Bedeutung komplett "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t\tSVM \t\tNaive Bayes\n",
      "Acc \t\t 0.501 \t\t 0.516\n",
      "Prec \t\t 0.520 \t\t 0.541\n",
      "Rec \t\t 0.578 \t\t 0.482\n",
      "FMeas \t\t 0.548 \t\t 0.510\n"
     ]
    }
   ],
   "source": [
    "# test the classifiers\n",
    "preds_svm = svm_classifier.predict(test_matrix)\n",
    "svm_acc = metrics.accuracy_score(labels_test, preds_svm)\n",
    "\n",
    "preds_nb = nb_classifier.predict(test_matrix)\n",
    "nb_acc = metrics.accuracy_score(labels_test, preds_nb)\n",
    "\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_test, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_test, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a statement about the results, we first have to look at the distribution of labels in the test dataset.\n",
    "An even simpler baseline we can use is a classifier that constantly predicts the class that is most common in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classifier that always predicts 'True' would get an accuracy of: 0.522\n"
     ]
    }
   ],
   "source": [
    "num_trues, num_falses = labels_test.value_counts()\n",
    "print(\"A classifier that always predicts 'True' would get an accuracy of: %.3f\" % (num_trues/labels_test.count()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
