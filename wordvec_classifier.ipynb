{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import naive_bayes, svm, metrics\n",
    "import pandas as pd\n",
    "# reset colwitdth options when running all cells \n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and group by day (all tweets and corresponding stock prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>hashtags</th>\n      <th>text</th>\n      <th>username</th>\n      <th>likes</th>\n      <th>replies</th>\n      <th>retweets</th>\n      <th>Open</th>\n      <th>Close</th>\n      <th>PriceUp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23516</th>\n      <td>2018-06-04</td>\n      <td>[]</td>\n      <td>So Tesla treats manufacturing people like shit...</td>\n      <td>Mark B. Spiegel</td>\n      <td>35</td>\n      <td>5</td>\n      <td>4</td>\n      <td>294.34</td>\n      <td>296.74</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>23517</th>\n      <td>2018-06-04</td>\n      <td>[]</td>\n      <td>Did you know Nikola Tesla has a whole ass book...</td>\n      <td>SEBEK RA</td>\n      <td>23</td>\n      <td>3</td>\n      <td>6</td>\n      <td>294.34</td>\n      <td>296.74</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>23518</th>\n      <td>2018-06-04</td>\n      <td>[Podsećanje, Insajder]</td>\n      <td>Grad se zbog koncesije bez naknade odrekao par...</td>\n      <td>Insajder</td>\n      <td>63</td>\n      <td>2</td>\n      <td>20</td>\n      <td>294.34</td>\n      <td>296.74</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       timestamp                hashtags  \\\n23516 2018-06-04                      []   \n23517 2018-06-04                      []   \n23518 2018-06-04  [Podsećanje, Insajder]   \n\n                                                    text         username  \\\n23516  So Tesla treats manufacturing people like shit...  Mark B. Spiegel   \n23517  Did you know Nikola Tesla has a whole ass book...         SEBEK RA   \n23518  Grad se zbog koncesije bez naknade odrekao par...         Insajder   \n\n       likes  replies  retweets    Open   Close  PriceUp  \n23516     35        5         4  294.34  296.74     True  \n23517     23        3         6  294.34  296.74     True  \n23518     63        2        20  294.34  296.74     True  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('processed_data/data_final_merged.json')\n",
    "# remove columns that were unexpectedly generated during saving\n",
    "# data.drop(columns=['level_0', 'index'], inplace=True)\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>hashtags</th>\n      <th>text</th>\n      <th>username</th>\n      <th>likes</th>\n      <th>replies</th>\n      <th>retweets</th>\n      <th>Open</th>\n      <th>Close</th>\n      <th>PriceUp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-02</td>\n      <td>[Muskwatchpic]</td>\n      <td>From SpaceX to Tesla, here are our biggest que...</td>\n      <td>Nerdist</td>\n      <td>37</td>\n      <td>5</td>\n      <td>10</td>\n      <td>312.00</td>\n      <td>320.53</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-03</td>\n      <td>[Tesla]</td>\n      <td>#Tesla just released record delivery numbers f...</td>\n      <td>InsideEVs Forum</td>\n      <td>11</td>\n      <td>1</td>\n      <td>5</td>\n      <td>321.00</td>\n      <td>317.25</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-04</td>\n      <td>[]</td>\n      <td>Tesla struggles with Model 3 production  pic.t...</td>\n      <td>Automotive News</td>\n      <td>5</td>\n      <td>0</td>\n      <td>5</td>\n      <td>312.87</td>\n      <td>314.62</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-05</td>\n      <td>[munilandhttps]</td>\n      <td>Head of Puerto Rico electric utility says they...</td>\n      <td>Cate Long</td>\n      <td>17</td>\n      <td>4</td>\n      <td>9</td>\n      <td>316.62</td>\n      <td>316.58</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-08</td>\n      <td>[]</td>\n      <td>“Bırakın doğruları gelecek söylesin ve herkesi...</td>\n      <td>[n]Beyin</td>\n      <td>324</td>\n      <td>2</td>\n      <td>86</td>\n      <td>316.00</td>\n      <td>336.41</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>2018-05-29</td>\n      <td>[]</td>\n      <td>You know Erin let us forget for a short period...</td>\n      <td>Darji</td>\n      <td>23</td>\n      <td>1</td>\n      <td>4</td>\n      <td>278.51</td>\n      <td>283.76</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>2018-05-30</td>\n      <td>[]</td>\n      <td>Tesla Autopilot blamed for crash with parked p...</td>\n      <td>BBC News Technology</td>\n      <td>11</td>\n      <td>3</td>\n      <td>11</td>\n      <td>283.29</td>\n      <td>291.72</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>2018-05-31</td>\n      <td>[Tesla]</td>\n      <td>Weekly #Tesla short update. $TSLA short intere...</td>\n      <td>Ihor Dusaniwsky</td>\n      <td>12</td>\n      <td>4</td>\n      <td>8</td>\n      <td>287.21</td>\n      <td>284.73</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>2018-06-01</td>\n      <td>[1u]</td>\n      <td>Tesla and Elon Musk face tough questions from ...</td>\n      <td>Minnesota AFL-CIO</td>\n      <td>19</td>\n      <td>0</td>\n      <td>10</td>\n      <td>285.86</td>\n      <td>291.82</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>2018-06-04</td>\n      <td>[]</td>\n      <td>It's great that Tesla can push rapid software ...</td>\n      <td>Forbes</td>\n      <td>52</td>\n      <td>5</td>\n      <td>22</td>\n      <td>294.34</td>\n      <td>296.74</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>103 rows × 10 columns</p>\n</div>",
      "text/plain": "     timestamp         hashtags  \\\n0   2018-01-02   [Muskwatchpic]   \n1   2018-01-03          [Tesla]   \n2   2018-01-04               []   \n3   2018-01-05  [munilandhttps]   \n4   2018-01-08               []   \n..         ...              ...   \n98  2018-05-29               []   \n99  2018-05-30               []   \n100 2018-05-31          [Tesla]   \n101 2018-06-01             [1u]   \n102 2018-06-04               []   \n\n                                                  text             username  \\\n0    From SpaceX to Tesla, here are our biggest que...              Nerdist   \n1    #Tesla just released record delivery numbers f...      InsideEVs Forum   \n2    Tesla struggles with Model 3 production  pic.t...      Automotive News   \n3    Head of Puerto Rico electric utility says they...            Cate Long   \n4    “Bırakın doğruları gelecek söylesin ve herkesi...             [n]Beyin   \n..                                                 ...                  ...   \n98   You know Erin let us forget for a short period...                Darji   \n99   Tesla Autopilot blamed for crash with parked p...  BBC News Technology   \n100  Weekly #Tesla short update. $TSLA short intere...      Ihor Dusaniwsky   \n101  Tesla and Elon Musk face tough questions from ...    Minnesota AFL-CIO   \n102  It's great that Tesla can push rapid software ...               Forbes   \n\n     likes  replies  retweets    Open   Close  PriceUp  \n0       37        5        10  312.00  320.53     True  \n1       11        1         5  321.00  317.25    False  \n2        5        0         5  312.87  314.62     True  \n3       17        4         9  316.62  316.58    False  \n4      324        2        86  316.00  336.41     True  \n..     ...      ...       ...     ...     ...      ...  \n98      23        1         4  278.51  283.76     True  \n99      11        3        11  283.29  291.72     True  \n100     12        4         8  287.21  284.73    False  \n101     19        0        10  285.86  291.82     True  \n102     52        5        22  294.34  296.74     True  \n\n[103 rows x 10 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group data by day\n",
    "daily_data = data.groupby(data['timestamp'], as_index=False)\n",
    "daily_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>103.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>228.339806</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>167.414922</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>26.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>159.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>184.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>235.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1376.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              text\ncount   103.000000\nmean    228.339806\nstd     167.414922\nmin      26.000000\n25%     159.000000\n50%     184.000000\n75%     235.500000\nmax    1376.000000"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count tweets per day to see if they're ok'ish distributed\n",
    "tweets_per_day = daily_data['text'].count()\n",
    "tweets_per_day.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have in average almost 50 tweets per day with a minimum of 6 tweets, which should be ok. The standard deviation is quite high too, but since we're so far only looking at individual tweets, this is absolutely ok. Even when we go for averaging the tweets of a single day, it should still be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp('2018-01-02 00:00:00')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get groups' names\n",
    "daily_data.groups.keys()\n",
    "groups = [name for name, _ in daily_data]\n",
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>hashtags</th>\n      <th>text</th>\n      <th>username</th>\n      <th>likes</th>\n      <th>replies</th>\n      <th>retweets</th>\n      <th>Open</th>\n      <th>Close</th>\n      <th>PriceUp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-02</td>\n      <td>[Muskwatchpic]</td>\n      <td>From SpaceX to Tesla, here are our biggest que...</td>\n      <td>Nerdist</td>\n      <td>37</td>\n      <td>5</td>\n      <td>10</td>\n      <td>312.0</td>\n      <td>320.53</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-02</td>\n      <td>[Snapchat, Uber, Twitter, Facebook, Tesla, Goo...</td>\n      <td>Here's how old these companies will be turning...</td>\n      <td>Imran</td>\n      <td>53</td>\n      <td>7</td>\n      <td>41</td>\n      <td>312.0</td>\n      <td>320.53</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-02</td>\n      <td>[Model3, Autopilot2, pasatealoelectrico, Tesla]</td>\n      <td>Primera prueba del @Tesla #Model3 en la nieve,...</td>\n      <td>PasatealoElectrico</td>\n      <td>23</td>\n      <td>0</td>\n      <td>6</td>\n      <td>312.0</td>\n      <td>320.53</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-02</td>\n      <td>[]</td>\n      <td>Know the whirr sound a Tesla makes?\\n\\nThat's ...</td>\n      <td>Elon Musk News</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>312.0</td>\n      <td>320.53</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-02</td>\n      <td>[]</td>\n      <td>In Norway, @Tesla finished Q4 with 3,753 Model...</td>\n      <td>Tesla Daily</td>\n      <td>28</td>\n      <td>0</td>\n      <td>6</td>\n      <td>312.0</td>\n      <td>320.53</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   timestamp                                           hashtags  \\\n0 2018-01-02                                     [Muskwatchpic]   \n1 2018-01-02  [Snapchat, Uber, Twitter, Facebook, Tesla, Goo...   \n2 2018-01-02    [Model3, Autopilot2, pasatealoelectrico, Tesla]   \n3 2018-01-02                                                 []   \n4 2018-01-02                                                 []   \n\n                                                text            username  \\\n0  From SpaceX to Tesla, here are our biggest que...             Nerdist   \n1  Here's how old these companies will be turning...               Imran   \n2  Primera prueba del @Tesla #Model3 en la nieve,...  PasatealoElectrico   \n3  Know the whirr sound a Tesla makes?\\n\\nThat's ...      Elon Musk News   \n4  In Norway, @Tesla finished Q4 with 3,753 Model...         Tesla Daily   \n\n   likes  replies  retweets   Open   Close  PriceUp  \n0     37        5        10  312.0  320.53     True  \n1     53        7        41  312.0  320.53     True  \n2     23        0         6  312.0  320.53     True  \n3      8        0         5  312.0  320.53     True  \n4     28        0         6  312.0  320.53     True  "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tweets from the first day\n",
    "first_day_data = daily_data.get_group(groups[0])\n",
    "first_day_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first very simple classifier using Word Vectors from spacy\n",
    "Use each tweet and predict whether it was written on a day where stock price has grown (PriceUp == True) or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-7-3c5cfd5b2d8a>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-3c5cfd5b2d8a>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    data = data.drop(index=empty_tweets\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "except:\n",
    "    import en_core_web_sm\n",
    "    nlp = en_core_web_sm.load()\n",
    "    \n",
    "tweet_vectors = []\n",
    "\n",
    "empty_tweets = []\n",
    "\n",
    "# Vectorize each tweet\n",
    "for i,tweet in enumerate(data.text):\n",
    "    tokens = nlp(tweet)\n",
    "    if len(tokens) > 0:\n",
    "        average_token= tokens[0].vector\n",
    "        summed_token_count = 1\n",
    "        for token in tokens[1:]:\n",
    "            # Only add to our sentence average token is token is not a stop word or if it's a negation\n",
    "            if token.dep_ == 'neg' or not token.is_stop:\n",
    "                average_token = average_token + token.vector\n",
    "                summed_token_count += 1\n",
    "        average_token = average_token / summed_token_count\n",
    "        tweet_vectors.append(average_token)\n",
    "    else:\n",
    "        empty_tweets.append(i)\n",
    "data = data.drop(index=empty_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the train and test sets\n",
    "tweets_train, tweets_test, labels_train, labels_test = train_test_split(tweet_vectors, data['PriceUp'], \n",
    "                                                   test_size=0.2, random_state=333, shuffle=True)\n",
    "len(tweets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue here...\n",
    "Vectorize the data... create a train and test matrix using word vectors from spacy... check if classifiers overfit to the training data... then evaluate on test data using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweets_train),len(labels_train))\n",
    "print(len(tweets_test),len(labels_test))\n",
    "print(type(tweets_train[0]))\n",
    "print(np.shape(tweets_train[0]))\n",
    "print(\"One vector: \", tweets_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tweets_train))\n",
    "print(type(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase number of training examples (by repeating them n times)\n",
    "n = 2\n",
    "train_matrix_n_times = tweets_train*n\n",
    "labels_train_n_times = pd.concat([labels_train]*n, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.LinearSVC(max_iter=int(1e6))\n",
    "svm_classifier.fit(train_matrix_n_times, labels_train_n_times)\n",
    "\n",
    "nb_classifier = naive_bayes.GaussianNB()\n",
    "nb_classifier.fit(train_matrix_n_times, labels_train_n_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if training was successful\n",
    "As we have not enough data, a working classifier should overfit to the training data and hence perfectly predict the labels of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if classifier has really overfitted to the data by testing it on the training data\n",
    "preds_svm = svm_classifier.predict(tweets_train)\n",
    "svm_acc = metrics.accuracy_score(labels_train, preds_svm)\n",
    "\n",
    "preds_nb = nb_classifier.predict(tweets_train)\n",
    "nb_acc = metrics.accuracy_score(labels_train, preds_nb)\n",
    "\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_train, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_train, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "Both classifiers reached quite poor performance when evaluating on even the training set. This could mean, we have no overfitting and have a hope for getting a bit generalization, but we believe there are other problems that can explain this observation: \n",
    "* das Language Model wurde auf anderen Daten trainiert... Die Dimensionen der Vektoren haben alle eine für unsere Aufgabe irrelevante Bedeutung.\n",
    "* Durschnitt eines Tweets verliert seine Bedeutung komplett "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the classifiers\n",
    "preds_svm = svm_classifier.predict(tweets_test)\n",
    "svm_acc = metrics.accuracy_score(labels_test, preds_svm)\n",
    "\n",
    "preds_nb = nb_classifier.predict(tweets_test)\n",
    "nb_acc = metrics.accuracy_score(labels_test, preds_nb)\n",
    "\n",
    "\n",
    "svm_prec, svm_rec, svm_fscore, svm_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_test, preds_svm, pos_label=True, average='binary')\n",
    "\n",
    "nb_prec, nb_rec, nb_fscore, nb_sup = \\\n",
    "metrics.precision_recall_fscore_support(labels_test, preds_nb, pos_label=True, average='binary')\n",
    "\n",
    "print('   \\t\\tSVM \\t\\tNaive Bayes')\n",
    "print('Acc \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_acc, nb_acc))\n",
    "print('Prec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_prec, nb_prec))\n",
    "print('Rec \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_rec, nb_rec))\n",
    "print('FMeas \\t\\t {0:.3f} \\t\\t {1:.3f}'.format(svm_fscore, nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a statement about the results, we first have to look at the distribution of labels in the test dataset.\n",
    "An even simpler baseline we can use is a classifier that constantly predicts the class that is most common in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trues, num_falses = labels_test.value_counts()\n",
    "print(\"A classifier that always predicts 'True' would get an accuracy of: %.3f\" % (num_trues/labels_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock Market Simulation:\n",
    "\n",
    "\n",
    "Use our classifier with the simulation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_market_simulation import load_stock_prices_from_json, Trader\n",
    "\n",
    "stock_prices = load_stock_prices_from_json()\n",
    "\n",
    "\n",
    "# Impact of the tweet of the classification of each tweet result\n",
    "data['impact'] = data.likes + data.replies + data.retweets\n",
    "# Recommendation obtained by the classifier\n",
    "data['recommendation'] = svm_classifier.predict(tweet_vectors)\n",
    "\n",
    "# Decide on the action of the day, based on the recommendations per tweet weighted by their impact.\n",
    "actions = []\n",
    "for day, group in data.groupby(data['timestamp'], as_index=False):\n",
    "     \n",
    "    weighted_recommendation = 0\n",
    "    # polarize the impact with the recommendation obtained by the classifier\n",
    "    for impact, recommendation in zip(group.impact, group.recommendation):\n",
    "        if recommendation:\n",
    "            weighted_recommendation += impact\n",
    "        else:\n",
    "            weighted_recommendation -= impact\n",
    "    # Normalize into [-1; 1] range\n",
    "    weighted_recommendation /= sum(group.impact)\n",
    "    # Experiment with thresholds for the actions on the stock market. If 3/4 of the impact are buy we buy, more impact is sell than buy, we sell.\n",
    "    actions.append([day, 1 if weighted_recommendation > 0.5 else -1 if weighted_recommendation < 0 else 0])\n",
    "\n",
    "actions = pd.DataFrame(actions, columns=['day', 'action'])\n",
    "actions = actions.set_index('day').resample('D').asfreq(fill_value=0)\n",
    "actions = actions.loc[stock_prices.index]['action'].to_list()\n",
    "\n",
    "print(actions)\n",
    "print(len(stock_prices))\n",
    "print(len(actions))\n",
    "\n",
    "simulation = Trader(stock_prices, actions)\n",
    "simulation.stock_action()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of the tweet of the classification of each tweet result\n",
    "data['impact'] = data.likes + data.replies + data.retweets\n",
    "# Recommendation obtained by the classifier\n",
    "data['recommendation'] = nb_classifier.predict(tweet_vectors)\n",
    "\n",
    "# Decide on the action of the day, based on the recommendations per tweet weighted by their impact.\n",
    "actions = []\n",
    "for day, group in data.groupby(data['timestamp'], as_index=False):\n",
    "     \n",
    "    weighted_recommendation = 0\n",
    "    for impact, recommendation in zip(group.impact, group.recommendation):\n",
    "        if recommendation:\n",
    "            weighted_recommendation += impact\n",
    "        else:\n",
    "            weighted_recommendation -= impact\n",
    "    weighted_recommendation /= sum(group.impact)\n",
    "    # Experiment with thresholds for the actions on the stock market\n",
    "    actions.append([day, 1 if weighted_recommendation > 0.5 else -1 if weighted_recommendation < 0 else 0])\n",
    "\n",
    "actions = pd.DataFrame(actions, columns=['day', 'action'])\n",
    "actions = actions.set_index('day').resample('D').asfreq(fill_value=0)\n",
    "actions = actions.loc[stock_prices.index]['action'].to_list()\n",
    "\n",
    "print(actions)\n",
    "print(len(stock_prices))\n",
    "print(len(actions))\n",
    "\n",
    "simulation = Trader(stock_prices, actions)\n",
    "simulation.stock_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_market_simulation import load_stock_prices_from_yahoo_finance\n",
    "display(load_stock_prices_from_yahoo_finance())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}